# MCP Interviewer

## Overview

MCP Interviewer is a CLI tool to evaluate an Model Context Protocol (MCP) servers' readiness for agentic use-cases. It inspects server capabilities and statistics, performs LLM-as-a-judge functional testing of tools, and generates a report.

## What MCP Interviewer Can Do

MCP Interviewer was developed to help mitigate MCP server compatibility issues with downstream clients by running functional tests and evaluations that identify potential problems prior to integration. The tool addresses critical compatibility challenges including API constraint violations (e.g. tool count limits, naming requirements), tool quality assessment (e.g. schema complexity, description clarity), functional testing with realistic workflows, and error handling verification, serving as a compatibility test suite that helps both server developers validate their implementations and users assess server quality before adoption.

## Intended Uses

MCP Interviewer is best suited for evaluating and assessing MCP servers before integration into workflows and applications. Specifically:

- Server developers validating their MCP implementations to maximize usefulness for downstream clients
- Server consumers evaluating third-party MCP servers before incorporating them into their systems or workflows, understanding server capabilities and potential compatibility issues

MCP Interviewer is intended to be used by domain experts who are independently capable of evaluating the quality of outputs before acting on them.

## Out-of-Scope Uses

MCP Interviewer is not well suited for:

- Real-time monitoring or debugging of MCP servers in live environments
- Any type of security auditing
- Performance benchmarking under load
- Certification or compliance validation for regulated industries
- Automated decision-making about server deployment 

We do not recommend using MCP Interviewer in commercial or real-world applications without further testing and development. It is being released for research purposes. 

MCP Interviewer was not designed or evaluated for all possible downstream purposes. Developers should consider its inherent limitations as they select use cases, and evaluate and mitigate for accuracy, safety, and fairness concerns specific to each intended downstream use. 

Without further testing and development, MCP Interviewer should not be used in sensitive domains where inaccurate outputs could suggest actions that lead to injury or negatively impact an individual's legal, financial, or life opportunities. 

We do not recommend using  MCP Interviewer in the context of high-risk decision making (e.g. in law enforcement, legal, finance, or healthcare). 

## Limitations

MCP Interviewer includes built-in validation constraints specifically designed for OpenAI model compatibility (tool count limits, naming patterns, token length restrictions) alongside general MCP best practices. When evaluating servers for use with other LLM providers, specify that provider's model in the --model parameter to ensure the functional testing and scoring align with that model's capabilities and constraints." 

MCP Interviewer was developed for research and experimental purposes. Further testing and validation are needed before considering its application in commercial or real-world scenarios. The MCP Python SDK executes arbitrary commands on the host machine, so users should run server commands in isolated containers and use external security tools to validate MCP server safety before running MCP Interviewer. Additionally, MCP Servers may have malicious or misleading tool metadata that may cause inaccurate MCP Interviewer outputs. Users should manually examine MCP Interviewer outputs for signs of malicious manipulation. 

MCP Interviewer was designed and tested using the English language. Performance in other languages may vary and should be assessed by someone who is both an expert in the expected outputs and a native speaker of that language. 

Outputs generated by AI may include factual errors, fabrication, or speculation. Users are responsible for assessing the accuracy of generated content. All decisions leveraging outputs of the system should be made with human oversight and not be based solely on system outputs. 

MCP Interviewer inherits any biases, errors, or omissions produced by its base model. Developers are advised to choose an appropriate base LLM/MLLM carefully, depending on the intended use case. 

MCP Interviewer can be run with any OpenAI-compatible API. Refer to your selected model’s model card to understand its capabilities and limitations. 

MCP Interviewer inherits any biases, errors, or omissions characteristic of its training data, which may be amplified by any AI-generated interpretations.  

There has not been a systematic effort to ensure that systems using MCP Interviewerare protected from security vulnerabilities such as indirect prompt injection attacks. Any systems using it should take proactive measures to harden their systems as appropriate. 

## Best Practices

Better performance can be achieved by: 

**Selecting appropriate evaluation modes:**

- By default, no LLM-as-a-judge evaluation is done.
- Manually validate outputs when using the `--judge*` options (`--judge`, `--judge-tools`, `--judge-test`) for experimental LLM-as-a-judge evaluations.

**Optimizing resource configuration:**

- Set appropriate `--timeout` values for servers with slow startup or response times 
- Use `--out-dir` to organize evaluation reports by server or version for systematic comparison 
- Run evaluations iteratively during development rather than only at the end 

**Choosing effective models:**

- Use capable models like gpt-5 or gpt-4.1 for more accurate LLM-based evaluations 
- Test with the same model family you plan to use in production for the most relevant results 

**Following systematic workflows:**

- Integrate mcp-interviewer into your development process early  
- Run evaluations after significant changes to server tools or capabilities 
- Compare reports across versions to track quality improvements over time 

**Interpreting report results:**

- Pay attention to constraint violations in the reports as these indicate compatibility issues
- Use the JSON output (mcp-interview.json) for programmatic analysis.


We strongly encourage users to use LLMs/MLLMs that support robust Responsible AI mitigations, such as Azure Open AI (AOAI) services. Such services continually update their safety and RAI mitigations with the latest industry standards for responsible use. For more on AOAI’s best practices when employing foundations models for scripts and applications: 

- [Blog post on responsible AI features in AOAI that were presented at Ignite 2023](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/announcing-new-ai-safety-amp-responsible-ai-features-in-azure/ba-p/3983686) 

- [Overview of Responsible AI practices for Azure OpenAI models](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/overview) 

- [Azure OpenAI Transparency Note](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/transparency-note) 

- [OpenAI’s Usage policies](https://openai.com/policies/usage-policies) 

- [Azure OpenAI’s Code of Conduct](https://learn.microsoft.com/en-us/legal/cognitive-services/openai/code-of-conduct) 

Users are responsible for sourcing their datasets legally and ethically. This could include securing appropriate rights, ensuring consent for use of audio/images, and/or the anonymization of data prior to use in research.    

Users are reminded to be mindful of data privacy concerns and are encouraged to review the privacy policies associated with any models and data storage solutions interfacing with MCP Interviewer .  

It is the user’s responsibility to ensure that the use of MCP Interviewer complies with relevant data protection regulations and organizational guidelines. 

Developers should follow transparency best practices and inform end-users they are interacting with an AI system. 

## License 

MIT License 

Nothing disclosed here, including the Out of Scope Uses section, should be interpreted as or deemed a restriction or modification to the license the code is released under. 

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft's Trademark & Brand Guidelines. Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship. Any use of third-party trademarks or logos are subject to those third-party's policies. 

## Contact 

This research was conducted by members of Microsoft Research.  We welcome feedback and collaboration from our audience. If you have suggestions, questions, or observe unexpected/offensive behavior in our technology, please contact us at mcp-interviewer@service.microsoft.com. 

If the team receives reports of undesired behavior or identifies issues independently, we will update this repository with appropriate mitigations. 
